{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Fail time slot-- 2015-01-05 01:50:00\n",
      "Max Fail time slot-- 2016-12-16 14:50:00\n"
     ]
    }
   ],
   "source": [
    "###----- Failure Data\n",
    "df_fail = pd.read_csv('Failure_data.csv') #csv with compatible col names\n",
    "df_fail.columns = df_fail.columns.str.upper()\n",
    "\n",
    "# Mutate columns\n",
    "df_fail['IMMEDIATE_MAINTENANCE'] = df_fail['BREAKDOWN_INDICATOR'] == 'X'\n",
    "df_fail['IMMEDIATE_MAINTENANCE'] = df_fail['IMMEDIATE_MAINTENANCE'].astype(int)\n",
    "\n",
    "# Get failure start/end slots\n",
    "df_fail['FAILURE_START'] = pd.to_datetime(df_fail['FAILURE_START_DATE'] + ' ' +  df_fail['FAILURE_START_TIME'])\n",
    "df_fail['FAILURE_END'] = df_fail['FAILURE_START'] + pd.to_timedelta(df_fail['ACTUAL_WORK'], unit='h')\n",
    "\n",
    "df_fail['FAILURE_START_MIN'] = df_fail['FAILURE_START'].dt.ceil('10min') # reading after failure will be erroneous\n",
    "df_fail['FAILURE_END_MAX'] = df_fail['FAILURE_END'].dt.floor('10min') # reading before fixing will be erroneous\n",
    "\n",
    "df_fail = df_fail[['FAILURE_START_MIN', 'FAILURE_END_MAX']]\n",
    "\n",
    "# List of fail slots\n",
    "fail_slots = []\n",
    "for row in np.arange(0, df_fail.shape[0]):\n",
    "    fail_slots.append(pd.date_range(df_fail['FAILURE_START_MIN'][row], df_fail['FAILURE_END_MAX'][row], freq='10min'))\n",
    "\n",
    "# List of all 10 min time slots when machine was under 'failed' state \n",
    "fail_list = [slot for sublist in fail_slots for slot in sublist]\n",
    "\n",
    "print('Min Fail time slot--', min(fail_list))\n",
    "print('Max Fail time slot--', max(fail_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###----- Sensor Data\n",
    "df_sensor = pd.read_csv('Sensor_data.csv', low_memory=False)\n",
    "df_sensor.columns = df_sensor.columns.str.upper()\n",
    "\n",
    "# Rename columns\n",
    "org_Sensor_cols = df_sensor.columns # original for lookup if needed\n",
    "new_colnm = dict(zip(df_sensor.columns[1:],['S'+ str(x) for x in range(1, df_sensor.shape[1])]))\n",
    "df_sensor.rename(new_colnm, inplace=True, axis=1)\n",
    "\n",
    "# Manipulate Columns\n",
    "# Timestamp\n",
    "df_sensor['TIMESTAMP'] = pd.to_datetime(df_sensor['TIMESTAMP'])\n",
    "df_sensor['DATE'] = df_sensor['TIMESTAMP'].dt.date\n",
    "df_sensor['TIME_SLOT_HR'] = df_sensor['TIMESTAMP'].dt.hour\n",
    "df_sensor['TIME_SLOT_MIN'] = pd.cut(df_sensor['TIMESTAMP'].dt.minute, bins=[0, 10, 20, 30, 40, 50, 60],labels=[1,2,3,4,5,6], right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATE\n",
      "2016-03-27    138\n",
      "2017-03-26    138\n",
      "2017-04-27      1\n",
      "Name: TIMESTAMP, dtype: int64\n",
      "\n",
      " Missing timeslots --  \n",
      " DatetimeIndex(['2016-03-27 01:00:00', '2016-03-27 01:10:00',\n",
      "               '2016-03-27 01:20:00', '2016-03-27 01:30:00',\n",
      "               '2016-03-27 01:40:00', '2016-03-27 01:50:00',\n",
      "               '2017-03-26 01:00:00', '2017-03-26 01:10:00',\n",
      "               '2017-03-26 01:20:00', '2017-03-26 01:30:00',\n",
      "               '2017-03-26 01:40:00', '2017-03-26 01:50:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n"
     ]
    }
   ],
   "source": [
    "# Check if data is present for all time slots as expected\n",
    "x = df_sensor.groupby(['DATE'])['TIMESTAMP'].nunique()\n",
    "print(x[x<144])\n",
    "\n",
    "\"\"\"Data is missing for 1 hour on 2 dates. Could be because of daylight saving start.\n",
    "The dates do not align with actual daylight saving time (maybe dates reshuffled for data security?).\n",
    "Anyhow, in that case, timestamps should be duplicated for some other 2 dates\"\"\"\n",
    "\n",
    "# Find missing time slots\n",
    "slot_list = pd.date_range(df_sensor['TIMESTAMP'].min(), df_sensor['TIMESTAMP'].max(), freq='10min')\n",
    "print('\\n','Missing timeslots -- ','\\n', slot_list[~slot_list.isin(df_sensor['TIMESTAMP'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109009, 52)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29820   2015-10-25 01:00:00\n",
       "29821   2015-10-25 01:10:00\n",
       "29822   2015-10-25 01:20:00\n",
       "29823   2015-10-25 01:30:00\n",
       "29824   2015-10-25 01:40:00\n",
       "29825   2015-10-25 01:50:00\n",
       "83244   2016-10-30 01:00:00\n",
       "83245   2016-10-30 01:10:00\n",
       "83246   2016-10-30 01:20:00\n",
       "83247   2016-10-30 01:30:00\n",
       "83248   2016-10-30 01:40:00\n",
       "83249   2016-10-30 01:50:00\n",
       "Name: TIMESTAMP, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_sensor.drop_duplicates().shape) # No duplicate rows present\n",
    "df_sensor['TIMESTAMP'][df_sensor['TIMESTAMP'].duplicated()]# Duplicate timestamps present\n",
    "# Seems like dates have been reshuffled although data reflects some inconsistency in timestamp similar to daytme saving\n",
    "# timestamps wont be tempered with as of now. May revisit those before modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset columns that are categorical + text\n",
    "sensor_text_col = ['S2', 'S3', 'S4', 'S6', 'S10', 'S11', 'S12', 'S13', 'S14', \n",
    "                  'S15', 'S16', 'S17', 'S18', 'S19', 'S20', 'S21', 'S23', 'S32', \n",
    "                  'S33', 'S37', 'S40', 'S43','S46', 'S47', 'S48']\n",
    "\n",
    "sensor_timecol = ['DATE', 'TIMESTAMP', 'TIME_SLOT_HR', 'TIME_SLOT_MIN']\n",
    "sensor_numcol = set(df_sensor.columns).difference(sensor_text_col, sensor_timecol)\n",
    "\n",
    "df_sensor.loc[:, df_sensor.columns.isin(sensor_numcol)].apply(lambda x : x.nunique()) \n",
    "# S22, S24, S31 have few unique values. These will act as low variance predictors and may need to be dropped from model\n",
    "\n",
    "##--- Process numeric columns\n",
    "# Replace text in numeric columns\n",
    "df_sensor_num_ = df_sensor[sensor_numcol].apply(lambda x:x.str.upper())\n",
    "\n",
    "for colnm in df_sensor_num_.columns:\n",
    "    df_sensor_num_[colnm] = df_sensor_num_[colnm].str.replace(\"I/O TIMEOUT\", '')\n",
    "    df_sensor_num_[colnm] = df_sensor_num_[colnm].str.replace(\"BAD INPUT\", '')\n",
    "    df_sensor_num_[colnm] = pd.to_numeric(df_sensor_num_[colnm])\n",
    "\n",
    "df_sensor_num_.isna().sum() \n",
    "\n",
    "\"\"\"s35 and s7 have large proportion of nan and replacing nan will change distribution of these variables. \n",
    "Replacing nan with mean ,min, max may mask the fact that bad imputs causing nan could be result of failure \n",
    "or indication that failure may happen in near future. \n",
    "A possible strategy could be to replace nan with 5*max of variable. This spike may be useful for learning process, \n",
    "or will atleast indicate that something changed for this observation period.\n",
    "Rest of the variables have few nans and can also be replaced with 5*max value \"\"\" \n",
    "\n",
    "df_sensor_num_ = df_sensor_num_.apply(lambda x:x.fillna(x.max()*5))\n",
    "\n",
    "##--- Process Text based cat columns\n",
    "df_sensor_text_ = df_sensor[sensor_text_col]\n",
    "df_sensor_text_ = df_sensor_text_.apply(lambda x:x.str.upper())\n",
    "\n",
    "df_sensor_text_['S33'] = df_sensor_text_['S33'].str.replace('?','')\n",
    "df_sensor_text_ = df_sensor_text_.replace({' ':'_', '/':''}, regex=True)\n",
    "\n",
    "df_sensor_text_ = pd.get_dummies(df_sensor_text_)\n",
    "\n",
    "## Concatenate all datasets\n",
    "df_sensor_clean = pd.concat([df_sensor[sensor_timecol], df_sensor_text_, df_sensor_num_], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Failure flag to data\n",
    "df_sensor_clean['FLG_FAIL'] = 0\n",
    "df_sensor_clean.loc[df_sensor_clean['TIMESTAMP'].isin(fail_list), 'FLG_FAIL'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matched time slots as expected?\n",
    "df_sensor_clean['FLG_FAIL'].sum() == sum([i>df_sensor_clean['TIMESTAMP'].min() for i in fail_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data for next step\n",
    "df_sensor_clean.to_csv('df_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
